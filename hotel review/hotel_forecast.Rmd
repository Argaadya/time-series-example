---
title: "Hotel Demand Forecasting"
author: "Arga Adyatama"
date: "5/8/2020"
output: 
 html_document:
  toc: true
  toc_float: true
  toc_depth: 3
  theme: flatly
  highlight: zenburn
  df_print: paged   
  code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = "center", warning = F, message = F)
```

# Background

```{r echo=FALSE}
knitr::include_graphics("asset/hotel.png")
```

Hospitality industry is growing, with more and more people spending their money for vacation and leisure activities. People may only lodge into a hotel when it's a holiday season or a special event, thus the demand for staying room is not equally distributed accross the year. To maximize the revenue gained by the hotel, the management often employed a pricing strategy, one of them being raising the room rate when the demand is high and making a promo when the demand is low. Thus, the ability to accurately forecast the future demand is very important and became a vital part on the pricing scheme. The demand for different segment of customer may differ and forecasting become harder as it may requires different model for different segment. 

This post will focus on fitting and tuning different forecasting models using `purrr` package on a real dataset .

# Library and Setup

Below is the list of required packages if you wish to reproduce the results. The full source code for this post is available at <a href = "https://github.com/Argaadya/time-series-example"> my github repository </a>.

```{r message=FALSE}
library(tidyverse)
library(lubridate)
library(ggthemes)
library(forecast)
library(tseries)
library(padr)
library(rsample)
library(scales)
```

# Hotel Demand Forecasting

## Import Data

Let's import the dataset. The data is acquired from <a href = "https://www.sciencedirect.com/science/article/pii/S2352340918315191"> **Nuno et al. (2019)** </a>. The data consists of around 119,390 booking transactions from 2 hotel: an anonymous city hotel from Lisbon and a resort hotel from Algarve. The dataset comprehend bookings due to arrive between the 1st of July of 2015 and the 31st of August 2017, including bookings that effectively arrived and bookings that were canceled. There is so much to explore from this data, but we will only focus on demand forecasting.

```{r}
hotel <- read.csv("hotel_bookings.csv")

head(hotel, 10)
```

Data Description:

* **hotel** : Hotel (H1 = Resort Hotel or H2 = City Hotel)
* **is_canceled** : Value indicating if the booking was canceled (1) or not (0)
* **lead_time** : Number of days that elapsed between the entering date of the booking into the PMS and the arrival date
* **arrival_date_year** : Year of arrival date
* **arrival_date_month** : Month of arrival date
* **arrival_date_week_number** : Week number of year for arrival date
* **arrival_date_day_of_month** : Day of arrival date
* **stays_in_weekend_nights** : Number of weekend nights (Saturday or Sunday) the guest stayed or booked to stay at the hotel
* **stays_in_week_nights** : Number of week nights (Monday to Friday) the guest stayed or booked to stay at the hotel
* **adults** : Number of adults
* **children** : Number of children
* **babies** : Number of babies
* **meal** : Type of meal booked. Categories are presented in standard hospitality meal packages: 

   - Undefined/SC – no meal package
   - BB – Bed & Breakfast
   - HB – Half board (breakfast and one other meal – usually dinner)
   - FB – Full board (breakfast, lunch and dinner)

* **country** : Country of origin. Categories are represented in the ISO 3155–3:2013 format
* **market_segment** : Market segment designation. In categories, the term “TA” means “Travel Agents” and “TO” means “Tour Operators”
* **distribution_channel** : Booking distribution channel. The term “TA” means “Travel Agents” and “TO” means “Tour Operators”
* **is_repeated_guest** : Value indicating if the booking name was from a repeated guest (1) or not (0)
* **previous_cancellations** : Number of previous bookings that were cancelled by the customer prior to the current booking
* **previous_bookings_not_canceled** : Number of previous bookings not cancelled by the customer prior to the current booking
* **reserved_room_type** : Code of room type reserved. Code is presented instead of designation for anonymity reasons.
* **assigned_room_type** : Code for the type of room assigned to the booking. Sometimes the assigned room type differs from the reserved room type due to hotel operation reasons (e.g. overbooking) or by customer request. Code is presented instead of designation for anonymity reasons.
* **booking_changes** : Number of changes/amendments made to the booking from the moment the booking was entered on the PMS until the moment of check-in or cancellation
* **deposit_type** : Indication on if the customer made a deposit to guarantee the booking. This variable can assume three categories: 
  
  - No Deposit – no deposit was made
  - Non Refund * a deposit was made in the value of the total stay cost
  - Refundable – a deposit was made with a value under the total cost of stay.
  
* **agent** : ID of the travel agency that made the booking
* **company** : ID of the company/entity that made the booking or responsible for paying the booking. ID is presented instead of designation for anonymity reasons
* **days_in_waiting_list** : Number of days the booking was in the waiting list before it was confirmed to the customer
* **customer_type** : Type of booking, assuming one of four categories:

  - Contract - when the booking has an allotment or other type of contract associated to it
  - Group – when the booking is associated to a group
  - Transient – when the booking is not part of a group or contract, and is not associated to other transient booking
  - Transient-party – when the booking is transient, but is associated to at least other transient booking
  
* **adr** : Average Daily Rate as defined by dividing the sum of all lodging transactions by the total number of staying nights
* **required_car_parking_spaces** : Number of car parking spaces required by the customer
* **total_of_special_requests** : Number of special requests made by the customer (e.g. twin bed or high floor)
* **reservation_status** : Reservation last status, assuming one of three categories: 

   - Canceled – booking was canceled by the customer
   - Check-Out – customer has checked in but already departed
   - No-Show – customer did not check-in and did inform the hotel of the reason why
   
* **reservation_status_date** : Date at which the last status was set. This variable can be used in conjunction with the *ReservationStatus* to understand when was the booking canceled or when did the customer checked-out of the hotel

## Data Preprocessing

Before we analyze the data, you may notice that the date is scattered in separate columns. We will unite them together to get a proper arrival date column. 

```{r}
hotel <- hotel %>% 
  unite("arrival_date", arrival_date_year, arrival_date_month, arrival_date_day_of_month, sep = "-") %>% 
  mutate(arrival_date = ymd(arrival_date))

head(hotel)
```

## Exploratory Data Analysis

### Market Segments

For each hotel, we have several market segments as mentioned earlier in the data description. In order to maximize our revenue, we will forecast the most profitable market segment. First, we will look at the number of transactions for each market segment on each hotel.

```{r}
hotel %>% 
  count(hotel, market_segment, is_canceled) %>% 
  group_by(hotel) %>% 
  mutate(total = sum(n),
         ratio = n/total,
         is_canceled = ifelse(is_canceled == 0, "No", "Yes")) %>% 
  ungroup() %>% 
  mutate(market_segment = tidytext::reorder_within(market_segment, ratio, hotel)) %>%  
  ggplot(aes(ratio, market_segment, fill = is_canceled)) +
  geom_col(position = "dodge") +
  labs(x = "Percentage", y = "Market Segment", 
       title = "Hotel Demand by Market Segment",
       fill = "Booking Canceled") +
  facet_wrap(~hotel, scales = "free_y") +
  scale_x_continuous(labels = percent_format(accuracy = 1)) +
  scale_fill_manual(values = c("skyblue", "firebrick")) +
  tidytext::scale_y_reordered() +
  theme_pander() +
  theme(legend.position = "top")
```

Based on the result, most of the booking done via travel agent, either online or offline, which combined together contributes more than 40% of the non-canceled total transactions. The other segment don't have much transactions, but perhaps we would like to see the revenue generated by each market segment by looking at the Average Daily Rate (ADR). Average Daily Rate as defined by dividing the sum of all lodging transactions by the total number of staying nights. Therefore, the higher ADR means more revenue generated for each staying night.

```{r}
hotel %>% 
  filter(is_canceled == F) %>% 
  group_by(hotel, market_segment) %>% 
  summarise(adr = sum(adr)) %>% 
  mutate(total = sum(adr),
         ratio = adr/total) %>% 
  ungroup() %>% 
  mutate(market_segment = tidytext::reorder_within(market_segment, ratio, hotel)) %>% 
  ggplot(aes(ratio, market_segment)) +
  geom_col(fill = "firebrick") +
  facet_wrap(~hotel, scales = "free_y") +
  tidytext::scale_y_reordered() +
  scale_x_continuous(labels = percent_format(accuracy = 1)) +
  theme_pander() +
  labs(x = NULL, y = NULL, 
       title = "ADR Contributions by Market Segments")
```

Total ADR generated from online travel agent is the highest both in the city hotel and the resort hotel. The segment of offline travel agent and direct has a little margin with each other, with direct segment has the higher contribution in resort hotel even though it has lower number of transactions. This give us the top 3 market segments, both in term of quantity and profitability. We will focus on this segments for the rest of the analysis.

### Time Series Analysis

We want to forecast the demand of lodging for both city hotel and resort hotel. Based on the previous exploration, we will use only the data from segment online travel agent, offline travel agent and direct. We will consider both canceled and non-canceled transactions to reflect the demand.

```{r}
hotel_city <- hotel %>%
  filter(hotel == "City Hotel",
         market_segment %>% str_detect("TA|Direct")) 

hotel_resort <- hotel %>%
  filter(hotel == "Resort Hotel",
         market_segment %>% str_detect("TA|Direct")) 

hotel_agg_city <- hotel_city %>% 
  group_by(arrival_date) %>% 
  summarise(demand = n())

hotel_agg_resort <- hotel_resort %>% 
  group_by(arrival_date) %>% 
  summarise(demand = n())

head(hotel_agg_city, 10)
```

Let's look at the series of demand for each hotel.

```{r}
hotel_agg_city   %>%
  mutate(hotel = "City Hotel") %>% 
  bind_rows(hotel_agg_resort %>% mutate(hotel = "Resort Hotel")) %>% 
  ggplot(aes(arrival_date, demand)) +
  geom_line(color = "dodgerblue4") +
  theme_pander() +
  facet_wrap(~hotel, ncol = 1) +
  labs(x = NULL, y = "Demand", title = "Hotel Booking Demand")
```

The demand for city hotel has a higher fluctuation compared to the resort hotel. This may be caused by several factors, including the room capacity, since we don't know the room capacity for each hotel. There are also some spikes in demand for city hotel during the late 2015. We will inspect further by dividing the series by market segment. We will also need to make the series have constant interval of time, which is a daily interval in our case.

```{r message=FALSE}
# summarizing data
hotel_agg_city <- hotel_city %>% 
  group_by(arrival_date, market_segment) %>% 
  summarise(demand = n())

hotel_agg_resort <- hotel_resort %>% 
  group_by(arrival_date, market_segment) %>% 
  summarise(demand = n())

# join city hotel and resort hotel
hotel_agg <- hotel_agg_city %>%
  mutate(hotel = "City Hotel") %>% 
  bind_rows(hotel_agg_resort %>% mutate(hotel = "Resort Hotel")) %>% 
  ungroup()

# padding
start_interval <-  ymd(range(hotel$arrival_date)[1])
end_interval <- ymd(range(hotel$arrival_date)[2])

hotel_pad <- hotel_agg %>% 
  group_by(hotel, market_segment) %>% 
  pad(start_val = start_interval, end_val = end_interval) %>% 
  replace_na(list(demand = 0)) %>% 
  ungroup()

hotel_pad %>% 
  ggplot(aes(arrival_date, demand, color = market_segment)) +
  geom_line() +
  theme_pander() +
  theme(legend.position = "top") +
  facet_wrap(~hotel, ncol = 1, scales = "free_y") +
  labs(x = NULL, y = "Demand", title = "Hotel Demand", color = NULL) +
  scale_color_manual(values = c("firebrick", "skyblue", "orange"))
```

The behaviour for each segment is quite different, so we will forecast them separately. At this point, we will have 6 different time series to be forecasted for 3 different segments on each hotel.

## Cross-Validation

We will split the data into training dataset and testing dataset, with testing dataset consists of the last 30 days from the full dataset.

```{r}
# get total number of observations
n_data <- hotel %>% count(arrival_date) %>% nrow()

# data train
hotel_train <- hotel_pad %>% 
  group_by(hotel, market_segment) %>% 
  slice( 1:(n_data-30) ) 

# data test
hotel_test <- hotel_pad %>% 
  group_by(hotel, market_segment) %>% 
  slice( -(n_data-30:n_data) )
```

## Time Series Specification

Since we have 6 series to be forecasted, manually fitting and tuning the model will take a long time. We will use `purrr` to efficiently fitting and evaluating the model in order to get the best model for each series based on the *Mean Absolute Error (MAE)* values. We don't use **Mean Absolute Percentage Error** because it did not perform really well when the actual data has or close to zero value, despite being easier to interpret.

First, we will nest the dataset, making our data into a list of 6 separate series.

```{r}
# nesting data train
train_list <- hotel_train %>% 
  select(-arrival_date) %>% 
  unite("series", hotel, market_segment, sep = "_") %>% 
  nest(-series)

# nesting data test
test_list <- hotel_test %>% 
  select(-arrival_date) %>% 
  unite("series", hotel, market_segment, sep = "_") %>% 
  nest(-series)

head(train_list)
```

The column `data` consists of a list of the demand for each series. The next step is to specify the seasonal period for the series. We will try several seasonal period, including:

- weekly seasonality 
- monthly seasonality 
- weekly and monthly seasonality (multi-seasonal)
- annual seasonality

```{r}
seasonal_forecast <- list(
  weekly = function(x) ts(x, frequency = 7),
  monthly = function(x) ts(x, frequency = 7*4),
  weekly_monthly = function(x) msts(x, seasonal.periods = c(7, 7*4)),
  annual = function(x) ts(x, frequency = 365)
) %>% 
  enframe(name = "season_name", value = "season_spec")
```

Next, we will specify the model the data will be fit into. The model includes:

- Holt-Winters
- ARIMA
- STL + ETS model
- STL + ARIMA

Below is the combination for each specification on each series. For 6 different series, we will have 4 different seasonality specification and 4 different models. Therefore, we will 96 different combinations. We will choose the best model based on the MAE value on the testing dataset.

```{r}
method_forecast <- list(
  holt_winter = function(x) HoltWinters(x),
  arima  = function(x) auto.arima(x),
  stl_ets = function(x) stlm(x, method = "ets"),
  stl_arima = function(x) stlm(x, method = "arima")
) %>% 
  enframe(name = "model_name", value = "model_spec")

# combine the data with the specification
train_crossing <- crossing(train_list, seasonal_forecast, method_forecast)

test_crossing <- crossing(test_list, seasonal_forecast, method_forecast)

train_crossing
```

Below is the result for our modeling process.

```{r warning= F}
# model fitting and evaluation
forecast_map <- map2(.x = train_crossing$data, 
                     .y = train_crossing$season_spec,
                     .f =  ~exec(.y,.x)) %>% 
  map2(.y = train_crossing$model_spec,
       .f =  ~exec(.y,.x)) %>% 
  map(forecast, h = 30) %>% 
  map2(.y = test_crossing$data, 
       .f = ~yardstick::mae_vec(.x$mean %>% as.numeric(), .y$demand))

train_crossing %>% 
  separate(series, c("hotel", "market_segment"), sep = "_") %>% 
  select_if(is.character) %>% 
  bind_cols(mae = forecast_map %>% as.numeric()) %>%
  arrange(mae)
```

Below is the best configuration for each series. To interpret the MAE values, we need to consider the range of the data, shown as the `range_min` and `range_max` of the data.

```{r message=FALSE}
# best configuration for each series
best_adjust <- train_crossing %>% 
  separate(series, c("hotel", "market_segment"), sep = "_") %>% 
  bind_cols(mae = forecast_map %>% as.numeric()) %>%
  group_by(hotel, market_segment) %>% 
  slice(1) %>% 
  arrange(mae)

# show the result
map(train_list$data, range) %>% 
  unlist() %>% 
  matrix(ncol = 2,byrow = T) %>% 
  as.data.frame() %>% 
  `names<-`(c("range_min", "range_max")) %>% 
  bind_cols(train_list) %>% 
  select_if(~is.list(.) == F) %>% 
  separate(series, c("hotel", "market_segment"), sep = "_") %>% 
  left_join(best_adjust) %>% 
  select_if(~is.list(.) == F) %>% 
  select(hotel, market_segment, season_name, model_name, everything())
```

Since we don't have much data, only two years of transactions, the model performance may not perform so well. However, judging from the MAE value, the performance is quite acceptable, with most of the error values are less than 10% of the range value. The best model from the series is the ARIMA model for City Hotel and Offline TA segment. 

If you wish to get the model or the forecasting result, just re-run the former steps using only the best adjustment. Here is one of the forecasting result.

```{r}
forecast_map <- map2(.x = best_adjust$data, 
                     .y = best_adjust$season_spec,
                     .f =  ~exec(.y,.x)) %>% 
  map2(.y = best_adjust$model_spec,
       .f =  ~exec(.y,.x)) %>% 
  map(forecast, h = 30)

data_test <- test_list$data[[2]] %>% ts(start = 3.090411, frequency = 365)

forecast_map[[2]] %>% 
  autoplot() +
  autolayer(data_test, series = "Data Test") +
  scale_color_manual(values = "firebrick") +
  labs(subtitle = "City Hotel, Offline TA/TO Segment",
       x = "Demand") +
  theme_pander() +
  theme(legend.position = "none")
```

# Conclusion

We have tried to do hotel demand forecasting using a real-world datasets with two years worth of data. We also have tried to analyze the series pattern for each hotel and segment and fit the best model for each one of them with a satisfying results. The next step perhaps is to enhance the model further either by using another time series model, incorporate predictor by the unused variables from the original dataset or transforming the data.